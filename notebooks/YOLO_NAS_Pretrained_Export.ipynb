{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "LFrYuNXjfW2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmuF9iKWTbdk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!git clone https://github.com/Deci-AI/super-gradients.git /content/super_gradients_folder\n",
        "! sed -i 's/sghub.deci.ai/sg-hub-nv.s3.amazonaws.com/' /content/super_gradients_folder/src/super_gradients/training/pretrained_models.py\n",
        "! sed -i 's/sghub.deci.ai/sg-hub-nv.s3.amazonaws.com/' /content/super_gradients_folder/src/super_gradients/training/utils/checkpoint_utils.py\n",
        "!pip install -e /content/super_gradients_folder\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select model"
      ],
      "metadata": {
        "id": "32ZL1W_3fbcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Models.YOLO_NAS_S\" #@param [\"Models.YOLO_NAS_S\", \"Models.YOLO_NAS_M\", \"Models.YOLO_NAS_L\"]\n",
        "input_width = 320 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
        "input_height = 320 #@param {type:\"slider\", min:32, max:4096, step:32}\n",
        "dtype = 'fp16' #@param [\"uint8\", \"fp16\", \"fp32\"]\n",
        "\n",
        "MODEL_FILENAME = f\"{model_name}.onnx\"\n",
        "MODEL_UINT8_FILENAME = f\"{model_name}_{dtype}_{input_width}x{input_height}.onnx\""
      ],
      "metadata": {
        "id": "O_f9J1KAOdGU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTB0jy_NNSFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec15410-15aa-4e2c-ae07-9acf5d418133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-03-13 17:34:36] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
            "[2025-03-13 17:34:43] INFO - utils.py - NumExpr defaulting to 2 threads.\n",
            "DEBUG:2025-03-13 17:34:49,789:jax._src.path:31: etils.epath found. Using etils.epath for file I/O.\n"
          ]
        }
      ],
      "source": [
        "from super_gradients.common.object_names import Models\n",
        "from super_gradients.training import models\n",
        "\n",
        "model = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")\n",
        "model.eval()\n",
        "model.prep_model_for_conversion(input_size=[1, 3, input_height, input_width])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GymUghyCNXem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "605162d7-7b5f-4aa3-f5ec-c5b90a2c242b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "It looks like your model does not have dataset preprocessing params properly set.\nThis may happen if you instantiated model from scratch and not trained it yet. \nHere are what you can do to fix this:\n1. Manually fill up dataset processing params via model.set_dataset_processing_params(...).\n2. Train your model first and then export it. Trainer will set_dataset_processing_params(...) for you.\n3. Instantiate a model using pretrained weights: models.get(..., pretrained_weights=\"coco\") \n4. Disable preprocessing by passing model.export(..., preprocessing=False). \n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModelHasNoPreprocessingParamsException\u001b[0m    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/module_interfaces/exportable_detector.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, output, confidence_threshold, nms_threshold, engine, quantization_mode, selective_quantizer, calibration_loader, calibration_method, calibration_batches, calibration_percentile, preprocessing, postprocessing, postprocessing_kwargs, batch_size, input_image_shape, input_image_channels, input_image_dtype, max_predictions_per_image, onnx_export_kwargs, onnx_simplify, device, output_predictions_format, num_pre_nms_predictions)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mpreprocessing_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preprocessing_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModelHasNoPreprocessingParamsException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/training/models/detection_models/yolo_nas/yolo_nas_variants.py\u001b[0m in \u001b[0;36mget_preprocessing_callback\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mModelHasNoPreprocessingParamsException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mpreprocessing_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_equivalent_photometric_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModelHasNoPreprocessingParamsException\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-7da1340eb637>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectionOutputFormatMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.export(\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;34m\"yolo_nas_s.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moutput_predictions_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDetectionOutputFormatMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAT_FORMAT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/super_gradients/module_interfaces/exportable_detector.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, output, confidence_threshold, nms_threshold, engine, quantization_mode, selective_quantizer, calibration_loader, calibration_method, calibration_batches, calibration_percentile, preprocessing, postprocessing, postprocessing_kwargs, batch_size, input_image_shape, input_image_channels, input_image_dtype, max_predictions_per_image, onnx_export_kwargs, onnx_simplify, device, output_predictions_format, num_pre_nms_predictions)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mpreprocessing_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preprocessing_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModelHasNoPreprocessingParamsException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0;34m\"It looks like your model does not have dataset preprocessing params properly set.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                     \u001b[0;34m\"This may happen if you instantiated model from scratch and not trained it yet. \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: It looks like your model does not have dataset preprocessing params properly set.\nThis may happen if you instantiated model from scratch and not trained it yet. \nHere are what you can do to fix this:\n1. Manually fill up dataset processing params via model.set_dataset_processing_params(...).\n2. Train your model first and then export it. Trainer will set_dataset_processing_params(...) for you.\n3. Instantiate a model using pretrained weights: models.get(..., pretrained_weights=\"coco\") \n4. Disable preprocessing by passing model.export(..., preprocessing=False). \n"
          ]
        }
      ],
      "source": [
        "from super_gradients.conversion import DetectionOutputFormatMode\n",
        "\n",
        "model.export(\n",
        "  MODEL_FILENAME,\n",
        "  output_predictions_format=DetectionOutputFormatMode.FLAT_FORMAT,\n",
        "  max_predictions_per_image=20,\n",
        "  confidence_threshold=0.4,\n",
        "  input_image_shape=(input_height, input_width)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "dummy_input = np.random.randint(0, 255, (1, 3, input_width, input_height)).astype(np.uint8)\n",
        "\n",
        "ort_session = ort.InferenceSession(MODEL_FILENAME, providers=[\"ROCMExecutionProvider\"])\n",
        "ort_session.run(None, {\"images\": dummy_input})"
      ],
      "metadata": {
        "id": "kOBHFhWVeNDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBhXV5g4Nh42"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('yolo_nas_s.onnx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}